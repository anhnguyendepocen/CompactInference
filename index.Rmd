--- 
title: "A Compact Guide to Classical Inference"
author: "Daniel Kaplan"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib]
biblio-style: apalike
link-citations: yes
description: ""
---

# Preface {-}

This book has a specific purpose: to help statistics instructors see that the kind of statistical inference usually taught in introductory statistics courses is unnecessarily complex. It introduces too much statistical terminology, it divides the subject into distinct methods when one method will do. It neglects to make simplifying assumptions that have miniscule effect and are completely justified by the intrinsic *imprecision* of useful statements in statistical inference.

By streamlining statistical inference, we make more room in our courses for important topics that have traditionally been ignored or treated too brusquely. Among these are covariates and causal inference. Streamlining  may help students achieve a healthier attitude toward inferential structures such as the p-value and statistical "significance" that have long been subject to criticism and, recently, calls from journals and professional societies to "abandon statistical significance." 

In the computer era, I believe that the central approach  to statistical inference should be *via* simulation. But this book is not at all about simulation. It's about the classical, pre-computer-era inference concepts and techniques that dominate today's (and yesteryear's) introductory statistics. Or, more precisely, it's about a way to teach the classical simple statistical settings -- difference between two means, difference between two proportions, slope of a regression line -- that unifies them and smooths the path to more general techniques such as multiple regression and ANOVA.

The primary innovation of this book is to use the F statistic as the basis for inference. Historically, F was  preceded by z and t. But, in most circumstances of interest today, z and t are effectively the same. And F is a generalization of t. Teaching t requires introducing standard errors, the idea of sampling distributions, and standard deviations. Teaching F does not.

To the experienced statistics teacher, many things will seem odd. I don't start with means and proportions. The variance is used extensively, but the standard deviation is not mentioned until Chapter 11 and, even then, it's an aside. The variance is defined using differences between pairs of data values rather than differences from the sample mean. In short, I'm not treating classical inference in a classical manner.

I hope that this short book will help instructors see a way forward to teaching a version of statistics more closely related to practice in today's world. Ironically, for a book about classical inference, that involves appropriate simplification and streamlining of topics that today consume disproportionate amounts of course time and student interest and energy.

*Daniel Kaplan, November 2019, Saint Paul, Minnesota*
 
