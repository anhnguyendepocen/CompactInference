# Confidence intervals

We use  effect size to quantify how a change in an explanatory input changes the output of the statistical model. 

Example: 

One way to express our uncertainty due to limited data in the effect size is to state it as an *interval* rather than  a single number. Classical inference developed several ways of finding an appropriate interval. This is called a confidence interval. 

## Confidence  intervals from F

In the case of the simplest models, where  $df = 1$, the interval can be calculated directly from F and the effect size B. The formula is

$CI = B (1 \pm \sqrt{4/F}).$

Example: 

## Why 4?


## Situations where F doesn't tell enough

When there are multiple effect sizes from  different variables.

Still, the F formula works pretty well so long  as the different explanatory  vectors are independent  of one  another (orthogonal). [DOES  IT]
